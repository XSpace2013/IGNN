{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils_data_new_code.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pJ9gR_dyi0V-"},"outputs":[],"source":["from sklearn.neighbors import kneighbors_graph\n","import networkx as nx\n","import numpy as np\n","import pandas as pd\n","import torch\n","import itertools\n","from sklearn.datasets import make_moons, make_circles\n","from torch_geometric.nn import GCNConv, ChebConv, SAGEConv\n","import pdb\n","import pickle5 as pickle\n","# import pickle\n","from torch.distributions.multivariate_normal import MultivariateNormal\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","''' 1. Non_graph Simulation Helpers '''\n","\n","\n","class graph_simulate_3node():\n","    def __init__(self, num_sample):\n","        self.num_sample = num_sample\n","        # Control the design of Z\n","        self.complex_X = False  # If Z are two-moon with rotation + raw H translation\n","        # Control how Z goes to X, where either \"small_averaging\" or \"disporportional\" is used\n","        self.small_averaging = False  # If A[i,i] += 10\n","        self.disporportional = False  # If A has different diagonal entries\n","        self.change_A = False\n","        self.P_square = False  # If X=P^2Z\n","        self.plot_X_Z = False\n","\n","    def get_full_data(self):\n","        X_full = []\n","        Y_full = []\n","        for i, Y in enumerate(itertools.product(*[[0, 1], [0, 1], [0, 1]])):\n","            print(f'Y={Y}')\n","            if self.complex_X:\n","                self.get_Z_from_Y_non_symmetric(Y)\n","            else:\n","                self.get_Z_from_Y(Y)\n","                # X, Z = self.get_X_from_Y(Y)\n","            self.get_X_from_Z()\n","            if i == 0:\n","                print(self.P)\n","            X_full.append(self.X.float())\n","            Y_full.append(torch.tensor(Y).repeat(self.num_sample, 1).float())\n","            if self.plot_X_Z:\n","                fig, ax = plt.subplots(2, 1, figsize=(8, 4))\n","                ax[0].scatter(self.Z.flatten(start_dim=0, end_dim=1)[\n","                    :, 0], self.Z.flatten(start_dim=0, end_dim=1)[:, 1])\n","                ax[0].set_title('Z')\n","                ax[1].scatter(self.X.flatten(start_dim=0, end_dim=1)[\n","                    :, 0], self.X.flatten(start_dim=0, end_dim=1)[:, 1])\n","                ax[1].set_title('X')\n","                fig.tight_layout()\n","                plt.show()\n","                plt.close()\n","        torch.manual_seed(1103)\n","        idx = torch.randperm(self.num_sample * 8)  # Randomly shuffle\n","        X_full, Y_full = torch.vstack(X_full)[idx], torch.vstack(Y_full)[idx]\n","        self.X_full, self.Y_full = X_full, Y_full\n","\n","    def get_Z_from_Y(self, Y):\n","        # Highly symmetric Z, can cause training issues\n","        mean0, mean1, cov = torch.tensor([0., 1.5]), torch.tensor(\n","            [0., -1.5]), (torch.eye(2) * 0.1)\n","        base0_dist = MultivariateNormal(mean0, cov)\n","        base1_dist = MultivariateNormal(mean1, cov)\n","        # First get Z\n","        Z = []\n","        for i, y in enumerate(Y):\n","            base_dist = base0_dist if y == 0 else base1_dist\n","            H_sample = base_dist.rsample(sample_shape=(self.num_sample,))\n","            offset = 4\n","            if i == 0:\n","                H_sample[:, 0] -= offset\n","            if i == 2:\n","                H_sample[:, 0] += offset\n","            Z.append(H_sample)\n","        Z = torch.hstack(Z)\n","        Z = Z.reshape(self.num_sample, 3, 2)\n","        self.Z = Z\n","\n","    def get_Z_from_Y_non_symmetric(self, Y):\n","        # Very non-convex Z, can cause learning difficulties\n","        mean0, mean1, cov = torch.tensor([0., 1.5]), torch.tensor(\n","            [0., -1.5]), (torch.eye(2) * 0.1)\n","        base0_dist = MultivariateNormal(mean0, cov)\n","        base1_dist = MultivariateNormal(mean1, cov)\n","        # First get Z\n","        Z = []\n","        moon_shift_dict = {0: [0.57, 0.73], 1: [-0.57, -0.73]}\n","        offset_dict = {0: [-4, 1], 1: [0, 2], 2: [4, 0]}\n","        theta = np.radians(270)\n","        c, s = np.cos(theta), np.sin(theta)\n","        rotate_matrix = np.array(((c, -s), (s, c)))\n","        for i, y in enumerate(Y):\n","            # Highly tailored, so we design depending on i and y\n","            # See notability image for example\n","            rstate = 1103 + i * 3 + y * 10\n","            moon_shift, offset = moon_shift_dict[y], offset_dict[i]\n","            if i == 0:\n","                X_np, y_np, _, _ = gen_two_moon_data(\n","                    2 * self.num_sample, 'two_moon', random_state=rstate)\n","                if y == 0:\n","                    # Upper moon, with shift\n","                    Z_sample = X_np[y_np == 0]\n","                else:\n","                    Z_sample = rotate_matrix.dot(X_np[y_np == 1].T).T\n","                Z_sample[:, 0] += moon_shift[0] + offset[0]\n","                Z_sample[:, 1] += moon_shift[1] + offset[1]\n","                Z_sample = torch.from_numpy(Z_sample).float()\n","            elif i == 1:\n","                if y == 0:\n","                    base_dist = base0_dist\n","                    Z_sample = base_dist.rsample(\n","                        sample_shape=(self.num_sample,))\n","                    Z_sample[:, 0] += offset[0]\n","                    Z_sample[:, 1] += offset[1]\n","                else:\n","                    X_np, y_np, _, _ = gen_two_moon_data(\n","                        2 * self.num_sample, 'two_moon', random_state=rstate)\n","                    Z_sample = X_np[y_np == 1]\n","                    Z_sample[:, 0] += moon_shift[0] + offset[0]\n","                    Z_sample[:, 1] += moon_shift[1] + offset[1]\n","                    Z_sample = torch.from_numpy(Z_sample).float()\n","            else:\n","                if y == 0:\n","                    X_np, y_np, _, _ = gen_two_moon_data(\n","                        2 * self.num_sample, 'two_moon', random_state=rstate)\n","                    Z_sample = rotate_matrix.dot(X_np[y_np == 0].T).T\n","                    Z_sample[:, 0] += moon_shift[0] + offset[0]\n","                    Z_sample[:, 1] += moon_shift[1] + offset[1]\n","                    Z_sample = torch.from_numpy(Z_sample).float()\n","                else:\n","                    base_dist = base1_dist\n","                    Z_sample = base_dist.rsample(\n","                        sample_shape=(self.num_sample,))\n","                    Z_sample[:, 0] += offset[0]\n","                    Z_sample[:, 1] += offset[1]\n","            Z.append(Z_sample)\n","        Z = torch.hstack(Z)\n","        Z = Z.reshape(self.num_sample, 3, 2)\n","        self.Z = Z\n","\n","    def get_X_from_Z(self):\n","        # Then get X from Z\n","        A = np.ones((3, 3))\n","        A[0, 2], A[2, 0] = 0, 0\n","        # Emphasize the connection between node 0 and 1, which is used in training.\n","        if self.change_A:\n","            A[0, 1] = 2\n","            A[1, 0] = 2\n","        if self.small_averaging:\n","            for i in range(3):\n","                A[i, i] += 10\n","        # Disporportional weight\n","        if self.disporportional:\n","            A[0, 0] = 2\n","            A[1, 1] = 3\n","            A[2, 2] = 5\n","        D_inv = np.diag(1 / np.sum(A, axis=1))\n","        P_mat = torch.from_numpy(D_inv.dot(A)).type(torch.float)\n","        if self.P_square:\n","            P_mat = P_mat @ P_mat\n","        self.P = P_mat\n","        X = P_mat @ self.Z\n","        self.X = X\n","\n","    def select_Y(self, Y_rows):\n","        for i, Y_row in enumerate(Y_rows):\n","            idx_temp = (self.Y_full == Y_row).all(dim=1).to(device)\n","            if i == 0:\n","                idx = idx_temp.clone()\n","            else:\n","                idx = torch.logical_or(idx, idx_temp)\n","        self.X_full, self.Y_full = self.X_full[idx], self.Y_full[idx]\n","\n","\n","class GP_graph():\n","    def __init__(self, num_sample, V):\n","        self.num_sample = num_sample\n","        self.V = V  # Must be a prime\n","        if isPrime(self.V) == False:\n","            raise ValueError('V Must be a prime for Chordal Cycle Graph')\n","\n","    def gen_1d_GP_data(self, Sigma_type='ChebNet'):\n","        if Sigma_type == 'ChebNet':\n","            self.get_graph_for_Cheb()\n","            # So sigma = I + L, normalized and rescaled\n","            layer = ChebConv(self.V, self.V, K=3).to(device)\n","            for name, param in layer.named_parameters():\n","                if name != 'bias':\n","                    with torch.no_grad():\n","                        weight_val = torch.eye(self.V).to(device)\n","                        a, b, c = 0.5, 0.1, 0.5\n","                        # By design, Sigma^{-1} = b*\\hat L + 2*c*\\hat L^2 + a*(1-c)*I\n","                        # For Sigma off-diagonal enteires large, b should be small, c reasonably large, and a*(1-c) not large\n","                        if '0' in name:\n","                            weight_val *= a\n","                        if '1' in name:\n","                            weight_val *= b\n","                        if '2' in name:\n","                            weight_val *= c\n","                        # To make sure covariance matrix invertible\n","                        param.data = weight_val\n","            X = torch.eye(self.V, self.V).to(device)\n","            # Get edge_weights so correlations are higher on off-diagonal\n","            n_edge = self.edge_index.shape[1]\n","            edge_weights = torch.ones(n_edge)\n","            # # Perturb on-diagnal entries\n","            # num_e = 0\n","            # for e in range(n_edge):\n","            #     if num_e > int(self.V/2):\n","            #         break\n","            #     edge = self.edge_index[:, e]\n","            #     which_e = (self.edge_index.T == edge).all(dim=1).cpu()\n","            #     e_loc = np.arange(n_edge)[which_e][0]\n","            #     if edge[0] == edge[1]:\n","            #         num_e += 1\n","            #         edge_weights[e_loc] *= 10\n","            # # Perturb off-diagnal entries\n","            # exclude_idx = []\n","            # for e in range(n_edge):\n","            #     if e > int((n_edge-self.V)/4):\n","            #         # e.g., only pertueb half of edge weights\n","            #         break\n","            #     if e in exclude_idx:\n","            #         continue\n","            #     edge = self.edge_index[:, e]\n","            #     if edge[0] != edge[1]:\n","            #         # Smaller values make Sigma larger, because it is the inverse\n","            #         mult = np.log(e+1)*1e-2\n","            #         edge_weights[e] *= mult\n","            #         oppo_edge = torch.tensor([edge[1], edge[0]]).to(device)\n","            #         which_e = (self.edge_index.T == oppo_edge).all(dim=1).cpu()\n","            #         oppo_e = np.arange(n_edge)[which_e][0]\n","            #         edge_weights[oppo_e] *= mult\n","            #         exclude_idx.append(oppo_e)\n","            self.edge_weights = edge_weights.to(device)\n","            Sigma_inv = layer(X, self.edge_index,\n","                              edge_weight=self.edge_weights)\n","            Sigma = torch.inverse(Sigma_inv).to(device)\n","            gaid = torch.diag(1 / torch.diag(Sigma)**0.5)\n","            Sigma_corr = gaid @ Sigma @ gaid\n","            print(f'Corr matrix: {Sigma_corr}')\n","            Unique_Y, counts_Y = torch.unique(\n","                torch.round(Sigma_corr, decimals=2), return_counts=True)\n","            idx = torch.abs(Unique_Y) > 0.1\n","            print(\n","                f'Correlation Dist. are {Unique_Y[idx].cpu().detach().tolist()}, \\n with frequency {counts_Y[idx].tolist()}')\n","            self.Sigma = Sigma\n","            fig, ax = plt.subplots(figsize=(4, 4))\n","            c = ax.matshow(Sigma_corr.cpu().detach().numpy())\n","            cbar_ax = fig.add_axes([1, 0.1, 0.1, 0.8])\n","            plt.colorbar(c, cax=cbar_ax)\n","            ax.set_title(r'Corr of $\\Sigma$')\n","        if Sigma_type == 'Local':\n","            # Consider KNN graph, where I just manually change the value of correlation matrix Sigma after created\n","            # NOTE, the 3-node graph has issue that \\Sigma^-1 not local\n","            self.get_graph_and_Sigma_for_local()\n","            self.edge_weights = torch.ones(self.edge_index.shape[1]).to(device)\n","            Sigma = self.Sigma\n","        Mu = torch.ones(self.V).to(device)\n","        X_dist = MultivariateNormal(Mu, Sigma)\n","        torch.manual_seed(1103)\n","        X_train = X_dist.rsample(sample_shape=(\n","            self.num_sample,)).cpu().detach().reshape(self.num_sample, self.V, 1)\n","        Y_train = torch.zeros(self.num_sample, self.V)\n","        self.X_train, self.Y_train = X_train, Y_train\n","        torch.manual_seed(111)\n","        X_test = X_dist.rsample(sample_shape=(\n","            self.num_sample,)).cpu().detach().reshape(self.num_sample, self.V, 1)\n","        Y_test = torch.zeros(self.num_sample, self.V)\n","        self.X_test, self.Y_test = X_test, Y_test\n","\n","    def get_graph_for_Cheb(self):\n","        # Get a graph where the locality is low (e.g., not easy to just go to another edge)\n","        G = nx.chordal_cycle_graph(self.V)\n","        G.add_edges_from([(i, i) for i in range(self.V)])\n","        fig, ax = plt.subplots(figsize=(4, 4))\n","        nx.draw(G, ax=ax, with_labels=True, node_color='white')\n","        self.fig = fig\n","        # edge_index = list(G.edges) # For erdo renyi graph\n","        edge_index = np.unique([list(i)[:2]\n","                               for i in list(G.edges)], axis=0).tolist()\n","        m = 0\n","        while m < len(edge_index):\n","            edge = edge_index[m]\n","            k, j = edge\n","            if [j, k] not in edge_index:\n","                edge_index.append([j, k])\n","            m += 1\n","        for i in range(self.V):\n","            if [i, i] not in edge_index:\n","                edge_index.append([i, i])\n","        edge_index = torch.tensor(edge_index).T.to(device)\n","        self.edge_index = edge_index\n","\n","    def get_graph_and_Sigma_for_local(self):\n","        # The KNN graph suggested by Prof. Cheng\n","        self.knn = False\n","        if self.knn:\n","            n, knn = self.V, 2\n","            np.random.seed(1103)\n","            T = np.sort(np.random.rand(n))\n","            X = np.array([[np.cos(np.pi * t), np.sin(np.pi * t)] for t in T])\n","            X = X + np.random.rand(X.shape[0], X.shape[1]) * 0.05\n","            A = kneighbors_graph(X, knn, mode='connectivity',\n","                                 include_self=True).toarray()\n","            A = A + A.T\n","            A[A > 0] = 1\n","            S = np.diag(np.ones(n)) * knn * 2 + A\n","            D = np.diag(1 / np.sqrt(np.sum(S, axis=1)))\n","            S = D @ S @ D\n","            S = (S + S.T) / 2\n","            # Convert to correlation matrix\n","            diag = np.sqrt(np.diag(np.diag(S)))\n","            gaid = np.linalg.inv(diag)\n","            S = gaid @ S @ gaid\n","            # NOTE, keep this small, as o/w S_inv would not be local\n","            offset = np.min(S[S > 0]) / n\n","            S[0, 1] += offset\n","            S[1, 0] += offset\n","            S[n - 2, n - 1] -= offset\n","            S[n - 1, n - 2] -= offset\n","            S_inv = np.linalg.inv(S)\n","            rows, cols = np.where(A == 1)\n","            edges = list(zip(rows.tolist(), cols.tolist()))\n","            self.edge_index = torch.tensor(\n","                [list(i) for i in edges]).T.to(device)\n","        else:\n","            self.edge_index = torch.tensor(\n","                [[0, 1, 1, 2, 0, 1, 2], [1, 0, 2, 1, 0, 1, 2]]).to(device)\n","            rho, rho1 = 0.6, -0.4\n","            S = np.array([[1, rho, 0], [rho, 1, rho1], [0, rho1, 1]])\n","            S_inv = np.linalg.inv(S)\n","            print(S_inv)  # Check if \"local\"\n","            X = np.zeros((3, 2))\n","        fig, ax = plt.subplots(2, 2, figsize=(\n","            8, 8), constrained_layout=True)\n","        gr = nx.Graph()\n","        gr.add_edges_from(self.edge_index.T.tolist())\n","        nx.draw(gr, ax=ax[0, 0], with_labels=True, node_color='white')\n","        ax[0, 1].plot(X[:, 0], X[:, 1], 'o')\n","        ax[1, 0].matshow(S)\n","        ax[1, 0].set_title(r'Corr of $\\Sigma$')\n","        c = ax[1, 1].matshow(S_inv)\n","        ax[1, 1].set_title(r'Corr of $\\Sigma^{-1}$')\n","        cbar_ax = fig.add_axes([1, 0.025, 0.1, 0.4])\n","        plt.colorbar(c, cax=cbar_ax)\n","        plt.show()\n","        plt.close()\n","        fig, ax = plt.subplots(figsize=(4, 4))\n","        gr = nx.Graph()\n","        gr.add_edges_from(self.edge_index.T.tolist())\n","        nx.draw(gr, ax=ax, with_labels=True, node_color='white')\n","        self.fig = fig\n","        self.Sigma = torch.from_numpy(S).float().to(device)\n","\n","\n","def isPrime(n):\n","    for i in range(2, int(n**0.5) + 1):\n","        if n % i == 0:\n","            return False\n","    return True\n","\n","\n","'''2. Real data helpers, Traffic '''\n","\n","\n","class trffic_data():\n","    def __init__(self, d):\n","        '''\n","        Input:\n","            d here means how long in the past we look at each node. It is thus the in-channel dimension\n","        '''\n","        self.d = d\n","\n","    def get_traffic_train_test(self, num_neighbor=3, sub=False):\n","        '''\n","            Description:\n","                Data are available hourly, with Yt,i = 1 (resp. 2) if the current traffic flow lies outside the upper (resp. lower) 90% quantile over the past four days of traffic flow of its nearest four neighbors based on sensor proximity.\n","        '''\n","        d = self.d\n","        # Traffic flow multi-class detection\n","        with open(f'flow_frame_train_0.7_no_drop_data.p', 'rb') as fp:\n","            Xtrain = pickle.load(fp)\n","        with open(f'flow_frame_test_0.7_no_drop_data.p', 'rb') as fp:\n","            Xtest = pickle.load(fp).to_numpy()\n","        with open(f'true_anomalies.p', 'rb') as fp:\n","            Yvals = pickle.load(fp).to_numpy()\n","        # Define edge index\n","        sensors = np.array(list(Xtrain.columns))\n","        Xtrain = Xtrain.to_numpy()\n","        scaler = StandardScaler()\n","        Xtrain = scaler.fit_transform(Xtrain)\n","        Xtest = scaler.fit_transform(Xtest)\n","        Ytrain = Yvals[:Xtrain.shape[0], :]\n","        Ytest = Yvals[Xtrain.shape[0]:, :]\n","        if sub:\n","            N = int(Xtrain.shape[0] / 2)  # 50% or /2 already pretty good\n","            N1 = int(Xtest.shape[0] / 2)\n","            Xtrain = Xtrain[-N:]\n","            Xtest = Xtest[:N1]\n","            Ytrain = Ytrain[-N:]\n","            Ytest = Ytest[:N1]\n","        with open(f'sensor_neighbors.p', 'rb') as fp:\n","            neighbor_dict = pickle.load(fp)\n","        # # Randomly select 15 nodes\n","        # np.random.seed(1103)\n","        # chosen_nodes = np.random.choice(len(sensors), 15, replace=False)\n","        # sensors = sensors[chosen_nodes]\n","        # Xtrain, Xtest, Ytrain, Ytest = Xtrain[:, chosen_nodes], Xtest[:,\n","        #                                                               chosen_nodes], Ytrain[:, chosen_nodes], Ytest[:, chosen_nodes]\n","        sensors_dict = {i: j for (i, j) in zip(sensors, range(len(sensors)))}\n","        edge_index = []\n","        # num_neighbor = 3\n","        for k, sensor in enumerate(sensors):\n","            neighbors = neighbor_dict[sensor]\n","            num_n = 0\n","            for p in range(len(sensors)):\n","                if num_n >= num_neighbor:\n","                    break\n","                if neighbors[p] in sensors_dict.keys():\n","                    edge_index.append([k, sensors_dict[neighbors[p]]])\n","                    num_n += 1\n","        edge_index = torch.from_numpy(np.array(edge_index).T).type(torch.long)\n","        # Define graphs, similarly as the solar data\n","        X_train = []\n","        X_test = []\n","        Y_train = []\n","        Y_test = []\n","        for t in range(d - 1, Xtrain.shape[0]):\n","            X_train.append(\n","                np.flip(Xtrain[t - d + 1:t + 1].T, 1))\n","            Y_train.append(Ytrain[t])\n","        for t in range(Xtest.shape[0]):\n","            if t < d - 1:\n","                temp = np.c_[np.flip(Xtest[:t + 1].T, 1),\n","                             np.flip(Xtrain[-(d - t) + 1:].T, 1)]\n","            else:\n","                temp = np.flip(Xtest[t - d + 1:t + 1].T, 1)\n","            X_test.append(temp)\n","            Y_test.append(Ytest[t])\n","        X_train = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in X_train])\n","        X_test = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in X_test])\n","        Y_train = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in Y_train])\n","        Y_test = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in Y_test])\n","        Y_train[Y_train == 2] = 0\n","        Y_test[Y_test == 2] = 0\n","        self.X_train, self.X_test, self.Y_train, self.Y_test, self.edge_index = X_train, X_test, Y_train, Y_test, edge_index\n","\n","    def plot_traffic(self):\n","        plt.rcParams['axes.titlesize'] = 20\n","        plt.rcParams['figure.titlesize'] = 28\n","        fig, axs = plt.subplots(3, 1, figsize=(\n","            3, 7), constrained_layout=True)\n","        G = nx.Graph()\n","        G.add_edges_from(self.edge_index.cpu().detach().numpy().T)\n","        pos = nx.circular_layout(G)\n","        i = 0\n","        nx.draw(G, pos, ax=axs[i], with_labels=True, node_color='lightblue')\n","        N, N1 = self.Y_train_sub.numel(), self.Y_test_sub.numel()\n","        colors = np.repeat('black', N)\n","        colors1 = np.repeat('black', N1)\n","        colors[(self.Y_train_sub.flatten() == 1).cpu(\n","        ).detach().numpy().flatten()] = 'red'\n","        colors1[(self.Y_test_sub.flatten() == 1).cpu(\n","        ).detach().numpy().flatten()] = 'red'\n","        Xtrain, Xtest = self.X_train_sub.flatten(\n","            start_dim=0, end_dim=1), self.X_test_sub.flatten(start_dim=0, end_dim=1)\n","        i += 1\n","        axs[i].scatter(Xtrain[:, 0], Xtrain[:, 1], s=1, color=colors)\n","        # axs[0].plot(Xtrain[:, 0], Xtrain[:, 1],\n","        #             linestyle='dashed', linewidth=0.075)\n","        axs[i].set_title('Train X')\n","        i += 1\n","        axs[i].scatter(Xtest[:, 0], Xtest[:, 1], s=1, color=colors1)\n","        # axs[1].plot(Xtest[:, 0], Xtest[:, 1],\n","        #             linestyle='dashed', linewidth=0.075)\n","        axs[i].set_title('Test X')\n","        self.fig = fig\n","        plt.show()\n","        plt.close()\n","\n","    def select_Y(self, Y_rows, train=True):\n","        if train:\n","            X, Y = self.X_train, self.Y_train\n","        else:\n","            X, Y = self.X_test, self.Y_test\n","        if Y_rows is None:\n","            if train:\n","                self.X_train_sub, self.Y_train_sub = X, Y\n","            else:\n","                self.X_test_sub, self.Y_test_sub = X, Y\n","        else:\n","            for i, Y_row in enumerate(Y_rows):\n","                idx_temp = (Y == Y_row).all(dim=1).to(device)\n","                if i == 0:\n","                    idx = idx_temp.clone()\n","                else:\n","                    idx = torch.logical_or(idx, idx_temp)\n","            if train:\n","                self.X_train_sub, self.Y_train_sub = X[idx], Y[idx]\n","            else:\n","                self.X_test_sub, self.Y_test_sub = X[idx], Y[idx]\n","\n","\n","''' 2. Real-data helpers, Solar '''\n","\n","\n","class solar_data():\n","    def __init__(self, num_obs_per_day, city):\n","        self.num_obs_per_day = num_obs_per_day\n","        self.city = city\n","        self.V = 10 if self.city == 'CA' else 0\n","        self.C = 2\n","\n","    def get_solar(self):\n","        graph_connect = {'CA': False, 'LA': True}\n","        DHI_2017 = get_DHI(self.city, '2017', self.V, self.num_obs_per_day)\n","        DHI_2018 = get_DHI(self.city, '2018', self.V, self.num_obs_per_day)\n","        DHI_full = np.r_[DHI_2017, DHI_2018]\n","        T = DHI_full.shape[0]\n","        N = int(T * 3 / 4)\n","        DHI_train, DHI_test = DHI_full[:N], DHI_full[N:]\n","        # Anomalies have same frequency as data\n","        get_anomaly(DHI_full, self.city, N)\n","        train_anom = np.loadtxt(\n","            f'{self.city}_anomalies_train.csv', delimiter=',')\n","        test_anom = np.loadtxt(\n","            f'{self.city}_anomalies_test.csv', delimiter=',')\n","        X_train, X_test, Y_train, Y_test = get_solar_train_test(\n","            DHI_train, DHI_test, train_anom, test_anom, d=self.C)\n","        # Each has dimension (N-by-V-by-C), where the response is only N-by-V\n","        X_train = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in X_train])\n","        X_test = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in X_test])\n","        Y_train = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in Y_train])\n","        Y_test = torch.stack([torch.from_numpy(val.copy()).type(\n","            torch.FloatTensor) for val in Y_test])\n","        count_train = np.unique(Y_train.numpy(), return_counts=True)[1]\n","        count_test = np.unique(Y_test.numpy(), return_counts=True)[1]\n","        print(\n","            f'#1/#0 in training data is {count_train[1]/count_train[0]}')\n","        print(f'#1/#0 in test data is {count_test[1]/count_test[0]}')\n","        fully_connected = graph_connect[self.city]\n","        edge_index = get_edge_list(\n","            Y_train, self.V, fully_connected)\n","        self.X_train, self.Y_train, self.X_test, self.Y_test = X_train, Y_train, X_test, Y_test\n","        self.edge_index = edge_index\n","\n","    def plot_solar(self):\n","        plt.rcParams['axes.titlesize'] = 20\n","        plt.rcParams['figure.titlesize'] = 28\n","        fig, axs = plt.subplots(3, 1, figsize=(\n","            3, 7), constrained_layout=True)\n","        G = nx.Graph()\n","        G.add_edges_from(self.edge_index.cpu().detach().numpy().T)\n","        pos = nx.circular_layout(G)\n","        i = 0\n","        nx.draw(G, pos, ax=axs[i], with_labels=True, node_color='lightblue')\n","        N, N1 = self.Y_train.numel(), self.Y_test.numel()\n","        colors = np.repeat('black', N)\n","        colors1 = np.repeat('black', N1)\n","        colors[(self.Y_train.flatten() == 1).cpu(\n","        ).detach().numpy().flatten()] = 'red'\n","        colors1[(self.Y_test.flatten() == 1).cpu(\n","        ).detach().numpy().flatten()] = 'red'\n","        Xtrain, Xtest = self.X_train.flatten(\n","            start_dim=0, end_dim=1), self.X_test.flatten(start_dim=0, end_dim=1)\n","        i += 1\n","        axs[i].scatter(Xtrain[:, 0], Xtrain[:, 1], s=1, color=colors)\n","        # axs[0].plot(Xtrain[:, 0], Xtrain[:, 1],\n","        #             linestyle='dashed', linewidth=0.075)\n","        axs[i].set_title('Train X')\n","        i += 1\n","        axs[i].scatter(Xtest[:, 0], Xtest[:, 1], s=1, color=colors1)\n","        # axs[1].plot(Xtest[:, 0], Xtest[:, 1],\n","        #             linestyle='dashed', linewidth=0.075)\n","        axs[i].set_title('Test X')\n","        self.fig = fig\n","        plt.show()\n","        plt.close()\n","\n","\n","def get_anomaly(raw_data, city, N):\n","    # NOTE: just run once is enough.\n","    T, V = raw_data.shape\n","    anomalies = np.zeros((T, V))\n","    # window = 15  # Used to be 30\n","    for l in range(V):\n","        for t in range(1, T):\n","            # past_window = np.arange(max(0, t-2*window), t, 2, dtype=int)\n","            # # past_at_l = raw_data[past_window, l]\n","            # past_at_l = raw_data[past_window]\n","            # Q1, Q3 = np.percentile(past_at_l, 25), np.percentile(past_at_l, 75)\n","            # IQR = Q3-Q1\n","            # lower_end1, lower_end2 = np.percentile(\n","            #     past_at_l, 5), np.percentile(past_at_l, 10)\n","            rate_inc = (raw_data[t, l] - raw_data[t - 1, l]\n","                        ) / raw_data[t - 1, l]\n","            # if raw_data[t, l] < Q1-IQR:\n","            # NOTE: use this a little arbitrary rule, as o/w too hard to do.\n","            if rate_inc > 1 or rate_inc < -0.5 or ((raw_data[t, l] < 40) and (raw_data[t - 1, l] < 35)):\n","                anomalies[t, l] = 1\n","    np.savetxt(f'{city}_anomalies_train.csv', anomalies[:N], delimiter=',')\n","    np.savetxt(f'{city}_anomalies_test.csv', anomalies[N:], delimiter=',')\n","\n","\n","def get_DHI(city, year, V, num_obs_per_day=2):\n","    # average_num_obs: how many observations we average over. Default is 24 so it is 12H\n","    full_data = pd.read_csv(f'{city}_{year}.csv')\n","    full_data = full_data['DHI'].to_numpy()\n","    days = 365\n","    mult = days * 48\n","    freq = int(24 / (num_obs_per_day - 1))\n","    T = days * num_obs_per_day\n","    X_array = np.zeros((T, V))\n","    for loc in range(V):\n","        loc_data = full_data[loc * mult:(loc + 1) * mult]\n","        for d in range(T):\n","            X_array[d, loc] = np.mean(loc_data[d * freq:d * freq + 24])\n","    return X_array\n","\n","\n","def get_solar_train_test(train_DHI, test_DHI, train_anom, test_anom, d=2):\n","    # d is the dimension of the input signal, which intuitively is the memory depth\n","    # The training data starts at index d, where each row is X=\\omega^-d_t=[\\omega_t-1,...,\\omega_t-d] \\in R^{K-by-d}\n","    X_train = []\n","    X_test = []\n","    Y_train = []\n","    Y_test = []\n","    N, N1 = train_DHI.shape[0], test_DHI.shape[0]\n","    scaler = StandardScaler()\n","    train_DHI = scaler.fit_transform(train_DHI)\n","    test_DHI = scaler.fit_transform(test_DHI)\n","    for t in range(d - 1, N):\n","        X_train.append(np.flip(train_DHI[t - d + 1:t + 1], 0).T)\n","        Y_train.append(train_anom[t])\n","    for t in range(N1):\n","        # Use raw DHI, including today\n","        if t < d - 1:\n","            temp = temp = np.r_[\n","                np.flip(test_DHI[:t + 1], 0), np.flip(train_DHI[-(d - t) + 1:], 0)]\n","        else:\n","            temp = np.flip(test_DHI[t - d + 1:t + 1], 0)\n","        X_test.append(temp.T)\n","        Y_test.append(test_anom[t])\n","    return [X_train, X_test, Y_train, Y_test]\n","\n","\n","def get_edge_list(Y_train, n=10, fully_connected=True):\n","    if fully_connected:\n","        edge_index = torch.from_numpy(\n","            np.array([[a, b] for a in range(n) for b in range(n)]).T).type(torch.long)\n","    else:\n","        # Infer edge connection in a nearest neighbor fashion, by including connection among node k and all nodes whose training labels are the most similar to k (e.g., in terms of equality). The reason is that this likely indicates influence.\n","        # Always include itself\n","        Y_temp = np.array(Y_train)\n","        edge_index = []\n","        num_include = 3  # four nodes, including itself\n","        for k in range(n):\n","            same_num = np.array([np.sum(Y_temp[:, k] == Y_temp[:, j])\n","                                 for j in range(Y_temp.shape[1])])\n","            include_ones = same_num.argsort()[-num_include:][::-1]\n","            for j in include_ones:\n","                edge_index.append([k, j])\n","        # Also, to ensure the connection is symmetric, I included all edges where there was a directed edge before\n","        print(f'{len(edge_index)} directed edges initially')\n","        m = 0\n","        while m < len(edge_index):\n","            edge = edge_index[m]\n","            k, j = edge\n","            if [j, k] in edge_index:\n","                # print(f'{[j, k]}' in edge')\n","                m += 1\n","                continue\n","            else:\n","                # print(f'{[j, k]} added b/c {[k, j]}' in graph')\n","                edge_index.append([j, k])\n","                m += 1\n","        print(f'{len(edge_index)} undirected edges after insertion')\n","        edge_index = torch.from_numpy(np.array(edge_index).T)\n","    return edge_index\n","\n","\n","'''3. Simulation non-graph helper and other helpers'''\n","\n","\n","def gen_two_moon_data(N, data_name, random_state=1103):\n","    if data_name == 'two_moon':\n","        X_np, y_np = make_moons(noise=0.05,\n","                                n_samples=N, random_state=random_state)\n","        X_np = StandardScaler().fit_transform(X_np)\n","        X = torch.from_numpy(X_np).float().to(device)\n","        y = torch.from_numpy(y_np).float().to(device)\n","    elif data_name == 'two_circles':\n","        X_np, y_np = make_circles(\n","            n_samples=N, noise=0.05, random_state=1103, factor=0.6)\n","        X = torch.from_numpy(X_np).float().to(device)\n","        y = torch.from_numpy(y_np).float().to(device)\n","    else:\n","        raise ValueError('Not considered yet')\n","    return [X_np, y_np, X, y]\n","\n","\n","def draw_graph(edge_index, edge_index_est, graph_type, overleaf_path):\n","    G = nx.Graph()\n","    G.add_edges_from(edge_index.cpu().detach().numpy().T)\n","    pos = nx.circular_layout(G)\n","    fig_network, ax1 = plt.subplots(1, 2, figsize=(8, 4))\n","    nx.draw(G, pos, with_labels=True, node_color='lightblue', ax=ax1[0])\n","    # ax1[0].set_title('True Graph')\n","    G = nx.Graph()\n","    G.add_edges_from(edge_index_est.cpu().detach().numpy().T)\n","    pos = nx.circular_layout(G)\n","    nx.draw(G, pos, with_labels=True, node_color='lightblue', ax=ax1[1])\n","    # ax1[1].set_title('Estimated Graph')\n","    fig_network.savefig(f'{overleaf_path}simulated_graph_{graph_type}.pdf',\n","                        dpi=200, bbox_inches='tight', pad_inches=0)\n","\n","\n","verts = [\n","    (-2.4142, 1.),\n","    (-1., 2.4142),\n","    (1.,  2.4142),\n","    (2.4142,  1.),\n","    (2.4142, -1.),\n","    (1., -2.4142),\n","    (-1., -2.4142),\n","    (-2.4142, -1.)\n","]\n","label_maps = {\n","    'all':  [0, 1, 2, 3, 4, 5, 6, 7],\n","    'some': [0, 0, 1, 1, 2, 2, 3, 3],\n","    'none': [0, 0, 0, 0, 0, 0, 0, 0],\n","}\n","\n","\n","def gen_8_gaussian_data(labels, N, random_state=0):\n","    # N denotes number of obs for all 8 Gaussian\n","    np.random.seed(random_state)\n","    mapping = label_maps[labels]\n","\n","    pos = np.random.normal(size=(N, 2), scale=0.2)\n","    labels = np.zeros((N, 8))\n","    n = N//8\n","\n","    for i, v in enumerate(verts):\n","        pos[i*n:(i+1)*n, :] += v\n","        labels[i*n:(i+1)*n, mapping[i]] = 1.\n","\n","    shuffling = np.random.permutation(N)\n","    pos = torch.tensor(pos[shuffling], dtype=torch.float)\n","    labels = torch.tensor(labels[shuffling], dtype=torch.float)\n","\n","    return pos, labels\n","\n","\n","##########\n"]}]}